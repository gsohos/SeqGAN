{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential GAN example\n",
    "\n",
    "We use as source Jane Austen's Pride and Prejudice to train a GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3485,
     "status": "ok",
     "timestamp": 1539071287733,
     "user": {
      "displayName": "Tomoaki Nakamura",
      "photoUrl": "",
      "userId": "09155123027556203739"
     },
     "user_tz": -540
    },
    "id": "BUaDU-WvPjyd",
    "outputId": "951f6630-9224-4d3d-f4de-c907bf7ff1f7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from SeqGAN.train import Trainer\n",
    "\n",
    "# Automatically reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HTBud0n4Pjyo"
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "B = 32 # batch size\n",
    "T = 25 # Max length of sentence\n",
    "g_E = 64 # Generator embedding size\n",
    "g_H = 64 # Generator LSTM hidden size\n",
    "g_lr = 1e-5\n",
    "d_E = 64 # Discriminator embedding and Highway network sizes\n",
    "d_H = d_E\n",
    "d_filter_sizes = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 15, 20] # filter sizes for CNNs\n",
    "d_num_filters = [100, 200, 200, 200, 200, 100, 100, 100, 100, 100, 160, 160] # num of filters for CNNs\n",
    "d_dropout = 0.0 # Discriminator dropout ratio\n",
    "d_lr = 1e-6\n",
    "\n",
    "n_sample=16 # Number of Monte Calro Search\n",
    "generate_samples = 20000 # Number of generated sentences\n",
    "\n",
    "\n",
    "# Pretraining parameters\n",
    "g_pre_lr = 1e-2\n",
    "d_pre_lr = 1e-4\n",
    "g_pre_epochs= 60\n",
    "d_pre_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d46UgjWHPjys"
   },
   "outputs": [],
   "source": [
    "top = os.getcwd()\n",
    "g_pre_weights_path = os.path.join(top, 'data', 'save', 'generator_pre.hdf5')\n",
    "d_pre_weights_path = os.path.join(top, 'data', 'save', 'discriminator_pre.hdf5')\n",
    "g_weights_path = os.path.join(top, 'data', 'save', 'generator.pkl')\n",
    "d_weights_path = os.path.join(top, 'data', 'save', 'discriminator.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a4K4JnbIPjyv"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(B, T, g_E, g_H, d_E, d_H, d_dropout,\n",
    "    g_lr=g_lr, d_lr=d_lr, n_sample=n_sample, generate_samples=generate_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 112971,
     "status": "ok",
     "timestamp": 1539056612885,
     "user": {
      "displayName": "Tomoaki Nakamura",
      "photoUrl": "",
      "userId": "09155123027556203739"
     },
     "user_tz": -540
    },
    "id": "7VLeFTIoPjyy",
    "outputId": "2b48a59a-46b3-4545-e731-470c730103dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator pre-training\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input (InputLayer)           (None, None)              0         \n",
      "_________________________________________________________________\n",
      "Embedding (Embedding)        (None, None, 64)          426304    \n",
      "_________________________________________________________________\n",
      "LSTM (LSTM)                  (None, None, 64)          33024     \n",
      "_________________________________________________________________\n",
      "TimeDenseSoftmax (TimeDistri (None, None, 6661)        432965    \n",
      "=================================================================\n",
      "Total params: 892,293\n",
      "Trainable params: 892,293\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/60\n",
      "133/133 [==============================] - 61s 457ms/step - loss: 6.1448\n",
      "Epoch 2/60\n",
      "133/133 [==============================] - 59s 441ms/step - loss: 4.8809\n",
      "Epoch 3/60\n",
      "133/133 [==============================] - 57s 428ms/step - loss: 4.4005\n",
      "Epoch 4/60\n",
      "133/133 [==============================] - 57s 428ms/step - loss: 4.0640\n",
      "Epoch 5/60\n",
      "133/133 [==============================] - 57s 432ms/step - loss: 3.8204\n",
      "Epoch 6/60\n",
      "133/133 [==============================] - 58s 439ms/step - loss: 3.6493\n",
      "Epoch 7/60\n",
      "133/133 [==============================] - 58s 437ms/step - loss: 3.5149\n",
      "Epoch 8/60\n",
      "133/133 [==============================] - 59s 441ms/step - loss: 3.4039\n",
      "Epoch 9/60\n",
      "133/133 [==============================] - 58s 433ms/step - loss: 3.3034\n",
      "Epoch 10/60\n",
      "133/133 [==============================] - 57s 431ms/step - loss: 3.2112\n",
      "Epoch 11/60\n",
      "133/133 [==============================] - 57s 429ms/step - loss: 3.1224\n",
      "Epoch 12/60\n",
      "133/133 [==============================] - 57s 431ms/step - loss: 3.0432\n",
      "Epoch 13/60\n",
      "133/133 [==============================] - 58s 435ms/step - loss: 2.9635\n",
      "Epoch 14/60\n",
      "133/133 [==============================] - 58s 436ms/step - loss: 2.8907\n",
      "Epoch 15/60\n",
      "133/133 [==============================] - 58s 437ms/step - loss: 2.8207\n",
      "Epoch 16/60\n",
      "133/133 [==============================] - 57s 430ms/step - loss: 2.7544\n",
      "Epoch 17/60\n",
      "133/133 [==============================] - 57s 430ms/step - loss: 2.6923\n",
      "Epoch 18/60\n",
      "133/133 [==============================] - 58s 436ms/step - loss: 2.6331\n",
      "Epoch 19/60\n",
      "133/133 [==============================] - 57s 431ms/step - loss: 2.5782\n",
      "Epoch 20/60\n",
      "133/133 [==============================] - 58s 436ms/step - loss: 2.5236\n",
      "Epoch 21/60\n",
      "133/133 [==============================] - 57s 426ms/step - loss: 2.4744\n",
      "Epoch 22/60\n",
      "133/133 [==============================] - 58s 434ms/step - loss: 2.4315\n",
      "Epoch 23/60\n",
      "133/133 [==============================] - 58s 435ms/step - loss: 2.3868\n",
      "Epoch 24/60\n",
      "133/133 [==============================] - 58s 435ms/step - loss: 2.3450\n",
      "Epoch 25/60\n",
      "133/133 [==============================] - 57s 429ms/step - loss: 2.3041\n",
      "Epoch 26/60\n",
      "133/133 [==============================] - 57s 430ms/step - loss: 2.2683\n",
      "Epoch 27/60\n",
      "133/133 [==============================] - 58s 435ms/step - loss: 2.2350\n",
      "Epoch 28/60\n",
      "133/133 [==============================] - 56s 424ms/step - loss: 2.2042\n",
      "Epoch 29/60\n",
      "133/133 [==============================] - 57s 432ms/step - loss: 2.1688\n",
      "Epoch 30/60\n",
      "133/133 [==============================] - 57s 430ms/step - loss: 2.1402\n",
      "Epoch 31/60\n",
      "133/133 [==============================] - 56s 424ms/step - loss: 2.1103\n",
      "Epoch 32/60\n",
      "133/133 [==============================] - 57s 430ms/step - loss: 2.0854\n",
      "Epoch 33/60\n",
      "133/133 [==============================] - 57s 428ms/step - loss: 2.0611\n",
      "Epoch 34/60\n",
      "133/133 [==============================] - 58s 436ms/step - loss: 2.0398\n",
      "Epoch 35/60\n",
      "133/133 [==============================] - 57s 431ms/step - loss: 2.0131\n",
      "Epoch 36/60\n",
      "133/133 [==============================] - 57s 432ms/step - loss: 1.9955\n",
      "Epoch 37/60\n",
      "133/133 [==============================] - 58s 435ms/step - loss: 1.9762\n",
      "Epoch 38/60\n",
      "133/133 [==============================] - 58s 433ms/step - loss: 1.9584\n",
      "Epoch 39/60\n",
      "133/133 [==============================] - 58s 433ms/step - loss: 1.9411\n",
      "Epoch 40/60\n",
      "133/133 [==============================] - 58s 437ms/step - loss: 1.9226\n",
      "Epoch 41/60\n",
      "133/133 [==============================] - 58s 434ms/step - loss: 1.9051\n",
      "Epoch 42/60\n",
      "133/133 [==============================] - 56s 423ms/step - loss: 1.8881\n",
      "Epoch 43/60\n",
      "133/133 [==============================] - 58s 434ms/step - loss: 1.8749\n",
      "Epoch 44/60\n",
      "133/133 [==============================] - 58s 433ms/step - loss: 1.8593\n",
      "Epoch 45/60\n",
      "133/133 [==============================] - 57s 429ms/step - loss: 1.8505\n",
      "Epoch 46/60\n",
      "133/133 [==============================] - 57s 432ms/step - loss: 1.8390\n",
      "Epoch 47/60\n",
      "133/133 [==============================] - 56s 424ms/step - loss: 1.8240\n",
      "Epoch 48/60\n",
      "133/133 [==============================] - 58s 432ms/step - loss: 1.8150\n",
      "Epoch 49/60\n",
      "133/133 [==============================] - 58s 436ms/step - loss: 1.8026\n",
      "Epoch 50/60\n",
      "133/133 [==============================] - 57s 431ms/step - loss: 1.7905\n",
      "Epoch 51/60\n",
      "133/133 [==============================] - 58s 434ms/step - loss: 1.7889\n",
      "Epoch 52/60\n",
      "133/133 [==============================] - 57s 429ms/step - loss: 1.7793\n",
      "Epoch 53/60\n",
      "133/133 [==============================] - 57s 430ms/step - loss: 1.7669\n",
      "Epoch 54/60\n",
      "133/133 [==============================] - 57s 430ms/step - loss: 1.7582\n",
      "Epoch 55/60\n",
      "133/133 [==============================] - 57s 431ms/step - loss: 1.7509\n",
      "Epoch 56/60\n",
      "133/133 [==============================] - 58s 434ms/step - loss: 1.7425\n",
      "Epoch 57/60\n",
      "133/133 [==============================] - 57s 430ms/step - loss: 1.7336\n",
      "Epoch 58/60\n",
      "133/133 [==============================] - 58s 434ms/step - loss: 1.7213\n",
      "Epoch 59/60\n",
      "133/133 [==============================] - 57s 432ms/step - loss: 1.7162\n",
      "Epoch 60/60\n",
      "133/133 [==============================] - 58s 434ms/step - loss: 1.7085\n",
      "Start Generating sentences\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input (InputLayer)              (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding (Embedding)           (None, None, 64)     426304      Input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 64)           33024       Embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Highway/FC_0 (Dense)            (None, 64)           4160        lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Highway/Gate_ratio_0 (Dense)    (None, 64)           4160        lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Highway/Gate_0 (Lambda)         (None, 64)           0           Highway/FC_0[0][0]               \n",
      "                                                                 lstm_4[0][0]                     \n",
      "                                                                 Highway/Gate_ratio_0[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "Dropout (Dropout)               (None, 64)           0           Highway/Gate_0[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "FC (Dense)                      (None, 1)            65          Dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 467,713\n",
      "Trainable params: 467,713\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Discriminator pre-training\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "758/758 [==============================] - 47s 62ms/step - loss: 0.4229\n"
     ]
    }
   ],
   "source": [
    "# Pretraining for adversarial training\n",
    "trainer.pre_train(\n",
    "    g_epochs=g_pre_epochs, d_epochs=d_pre_epochs,\n",
    "    g_pre_path=g_pre_weights_path, d_pre_path=d_pre_weights_path,\n",
    "    g_lr=g_pre_lr, d_lr=d_pre_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRjLhGCxPjy1"
   },
   "outputs": [],
   "source": [
    "trainer.load_pre_train(g_pre_weights_path, d_pre_weights_path)\n",
    "trainer.reflect_pre_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1020
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 240609,
     "status": "ok",
     "timestamp": 1539071601028,
     "user": {
      "displayName": "Tomoaki Nakamura",
      "photoUrl": "",
      "userId": "09155123027556203739"
     },
     "user_tz": -540
    },
    "id": "LdT2UQgNXD0j",
    "outputId": "d32d28f5-d322-4535-dded-6a35e31b07c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: 0.247, Episode end\n",
      "そこに立って一字抜ける裏に。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "それで私はよほどの上へ避暑を待つより外に不思議の外へいいか事を嘘と発議し\n",
      "けれども驚いて堪らなかったのです。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "奥さんと呼び掛ける事実、その言葉を恐れたのです。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "ただ散歩がてらに見ると、葬式の人で置くような自殺したような心持です。</S><PAD>\n",
      "その日ちょうど医者の人を出帆するものというものについて、彼の名を散歩がこびり付いています。\n",
      "つまりお嬢さんを恐れているのは急にのた希望を通す機会であったかと疑われますが\n",
      "要するに私からいえば、私は頭をいう気味でなく、言訳の事もありました。</S><PAD>\n",
      "私はまだ例の叔父を兄に会わないところでした。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "私はＫの墓までも動く種であったがあるかも知れません。</S><PAD><PAD><PAD><PAD><PAD>\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/1\n",
      "758/758 [==============================] - 46s 61ms/step - loss: 0.3692\n",
      "Reward: 0.281, Episode end\n",
      "——もうあなたとも突然私の利かないんだよ。学校から聞いたが私になりましたがね\n",
      "あの時敵にもいって、「行き出したけれども、お前も学生ぐらい人といってからも残ら\n",
      "この際彼の叔父が私の眼に何の蟠や人はほとんど起らなかった。</S><PAD><PAD><PAD>\n",
      "どうだかという好意、休みに共通な態度に付け加えて、毎夜思った時にはたしかにの旨いもの\n",
      "お嬢さんも私には翌日に至るまで美しい一対の男があるが、奥さんに向って、聟を気\n",
      "それが横に乏しい人が厭な響きがかなりと思います。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "彼らは、強い言葉を着けよました。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "けれどもその交際が黒ずんだのだという決心を試みる人あったが、躑躅が思った女には方角\n",
      "時にはどんなに変って仮病を遥かに始めた時です。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "つまりこの叔父の言葉が父の頭を※［＃「だという私が、卑怯なんでしょう。</S><PAD><PAD>\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1/1\n",
      "758/758 [==============================] - 41s 54ms/step - loss: 0.3631\n",
      "Reward: 0.289, Episode end\n",
      "不馴れの事ができなかったのを発見したのです。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "また例のところがありますために、父は私を置き去りた。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "玄関の方へ急がにもなりませんでした。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "その頁は振舞いませんでした。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "そうしてその初夏で、お嬢さんが揃ってさっさとどこの専門と考えていました。</S><PAD><PAD><PAD><PAD>\n",
      "私は再び笑ってくるよりずっとあった。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "すると奥さんの談話はただ道づれをしようというハイカラで構わないだろうとした。</S><PAD><PAD><PAD>\n",
      "先生はただ機会が例がほとんど私だって、その道を見るや否や学校へ出ないだけで、私の\n",
      "結婚する人らしい心を知っていました。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "日蓮のようにも答えなかった私の眼を擦ります。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/george/github/kerasSeqGAN/data/kokoro_parsed.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-216e155d6e27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/kerasSeqGAN/SeqGAN/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, steps, g_steps, d_steps, d_epochs, g_weights_path, d_weights_path, verbose, head)\u001b[0m\n\u001b[1;32m    154\u001b[0m                     \u001b[0mpath_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_pos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                     \u001b[0mpath_neg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_neg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m                     \u001b[0mB\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m                     shuffle=True)\n\u001b[1;32m    158\u001b[0m                 self.discriminator.fit_generator(\n",
      "\u001b[0;32m~/github/kerasSeqGAN/SeqGAN/utils.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_pos, path_neg, B, T, min_count, shuffle)\u001b[0m\n\u001b[1;32m    296\u001b[0m         }\n\u001b[1;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNK_TOKEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m         \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/kerasSeqGAN/SeqGAN/utils.py\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     38\u001b[0m     '''\n\u001b[1;32m     39\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# split word with space\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/george/github/kerasSeqGAN/data/kokoro_parsed.txt'"
     ]
    }
   ],
   "source": [
    "trainer.train(steps=10, g_steps=1, head=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cy4eZ6cAPjy4"
   },
   "outputs": [],
   "source": [
    "trainer.save(g_weights_path, d_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LEU5CzmBPjy6"
   },
   "outputs": [],
   "source": [
    "trainer.load(g_weights_path,\n",
    "             d_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 774,
     "status": "ok",
     "timestamp": 1539071798978,
     "user": {
      "displayName": "Tomoaki Nakamura",
      "photoUrl": "",
      "userId": "09155123027556203739"
     },
     "user_tz": -540
    },
    "id": "6veelo6nPjy7",
    "outputId": "52240b1a-1aed-4057-9339-102c76f6ffa0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1, 0.953: 私は彼の魔法棒のために一度に化石されたようなものです。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: 大したものを持ってやるから、その推測を突き留めてどこへ行って、止しているだろうと</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.005: 母は笑ってしまった。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.003: 私が目的どおり市に残して行くのかと尋ねました。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.003: それが希望にいう事もあります。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: しかし定めて皆な返事がある匂いは、あなたの事にはいりを見詰めていた。</S><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: 先生の留守の間、母の予期した薄暗い気分でも、朝でも黒い影が有難いものを、彼</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.004: それを想像する日の談話を呼ぶものを蔽い被せた。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.005: 妻は彼の虚に付け込んだのです。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.006: 「「本当いう気があった。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: Ｋと私は必ず「死んだつもりで玄関にしていたからいたように、とうとう堪え切れ</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: お嬢さんはまた突然先生からいい出して礼を私に物語った私が一向平気で見た。</S><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.001: 実をいうと私は主人の目的物としてをやりました。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "1, 1.000: その上奥さんの調子や、お嬢さんの態度が、始終私を突ッつくように刺戟するのですから、私はなお辛かったのです。</S><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: しかし医者が事態をますます人間がなかったという考えが一つも与えられてしまった。</S><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.002: 「私はそのまましておいて、僕がいった。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.005: 私は私自身のうちではありませんでした。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.002: その笑いの日はみんな一つ家にはいつの間にか憐れな虫のです。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: 私は酒を理解して高い処に、あなたもいった後のわが家を突きつつあるらしく見えまし</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "1, 0.995: 私はその時彼に向って残酷な答を与えたのです。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.004: 私宛で書き残しられなかった。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.001: 私は永久にして行李を読んだ。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.002: 兄と奥さんが本当に口が来るまで双方といってしまった。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: ただ大きな銀杏が主張していなかった人、そうして心のうちで、空を出す時も、私</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.002: 私は座敷へはいってどんなにこんな場合二人の面影を兄に教えてやって来た。</S><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: その時先生の手紙から得た事を喜んでもありません。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.001: Ｋの自然は、あまり仰山な立場から、羨まし極出す時は、雑司ヶ谷と足の区別を了解し</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: するとその医者の穿く猿股一つの樹がいうまでも、これからＫと結婚しました。</S><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "1, 0.966: 私にはその答えが謙遜過ぎてかえって世間を冷評するようにも聞こえた。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.006: お嬢さんも何もしていませんでした。</S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: 私はつづいて眼で茶を飲み、下宿人のものではありませんでした。</S><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n",
      "0, 0.000: Ｋの精神がかいと思うと、安心するような意味になった。</S><PAD><PAD><PAD><PAD><PAD><PAD></S><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>\n"
     ]
    }
   ],
   "source": [
    "trainer.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D5icM7-Y0bsb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "main.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
